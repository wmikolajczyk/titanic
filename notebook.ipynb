{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "holdout = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "def process_missing(df):\n",
    "    \"\"\"Handle various missing values from the data set\n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    holdout = process_missing(holdout)\n",
    "    \"\"\"\n",
    "    df[\"Fare\"] = df[\"Fare\"].fillna(train[\"Fare\"].mean())\n",
    "    df[\"Embarked\"] = df[\"Embarked\"].fillna(\"S\")\n",
    "    return df\n",
    "\n",
    "def process_age(df):\n",
    "    \"\"\"Process the Age column into pre-defined 'bins' \n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train = process_age(train)\n",
    "    \"\"\"\n",
    "    df[\"Age\"] = df[\"Age\"].fillna(-0.5)\n",
    "    cut_points = [-1,0,5,12,18,35,60,100]\n",
    "    label_names = [\"Missing\",\"Infant\",\"Child\",\"Teenager\",\"Young Adult\",\"Adult\",\"Senior\"]\n",
    "    df[\"Age_categories\"] = pd.cut(df[\"Age\"],cut_points,labels=label_names)\n",
    "    return df\n",
    "\n",
    "def process_fare(df):\n",
    "    \"\"\"Process the Fare column into pre-defined 'bins' \n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train = process_fare(train)\n",
    "    \"\"\"\n",
    "    cut_points = [-1,12,50,100,1000]\n",
    "    label_names = [\"0-12\",\"12-50\",\"50-100\",\"100+\"]\n",
    "    df[\"Fare_categories\"] = pd.cut(df[\"Fare\"],cut_points,labels=label_names)\n",
    "    return df\n",
    "\n",
    "def process_cabin(df):\n",
    "    \"\"\"Process the Cabin column into pre-defined 'bins' \n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train process_cabin(train)\n",
    "    \"\"\"\n",
    "    df[\"Cabin_type\"] = df[\"Cabin\"].str[0]\n",
    "    df[\"Cabin_type\"] = df[\"Cabin_type\"].fillna(\"Unknown\")\n",
    "    df = df.drop('Cabin',axis=1)\n",
    "    return df\n",
    "\n",
    "def process_titles(df):\n",
    "    \"\"\"Extract and categorize the title from the name column \n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train = process_titles(train)\n",
    "    \"\"\"\n",
    "    titles = {\n",
    "        \"Mr\" :         \"Mr\",\n",
    "        \"Mme\":         \"Mrs\",\n",
    "        \"Ms\":          \"Mrs\",\n",
    "        \"Mrs\" :        \"Mrs\",\n",
    "        \"Master\" :     \"Master\",\n",
    "        \"Mlle\":        \"Miss\",\n",
    "        \"Miss\" :       \"Miss\",\n",
    "        \"Capt\":        \"Officer\",\n",
    "        \"Col\":         \"Officer\",\n",
    "        \"Major\":       \"Officer\",\n",
    "        \"Dr\":          \"Officer\",\n",
    "        \"Rev\":         \"Officer\",\n",
    "        \"Jonkheer\":    \"Royalty\",\n",
    "        \"Don\":         \"Royalty\",\n",
    "        \"Sir\" :        \"Royalty\",\n",
    "        \"Countess\":    \"Royalty\",\n",
    "        \"Dona\":        \"Royalty\",\n",
    "        \"Lady\" :       \"Royalty\"\n",
    "    }\n",
    "    extracted_titles = df[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\n",
    "    df[\"Title\"] = extracted_titles.map(titles)\n",
    "    return df\n",
    "\n",
    "def create_dummies(df,column_name):\n",
    "    \"\"\"Create Dummy Columns (One Hot Encoding) from a single Column\n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train = create_dummies(train,\"Age\")\n",
    "    \"\"\"\n",
    "    dummies = pd.get_dummies(df[column_name],prefix=column_name)\n",
    "    df = pd.concat([df,dummies],axis=1)\n",
    "    return df\n",
    "\n",
    "def preprocess_df(df):\n",
    "    df = process_missing(df)\n",
    "    df = process_age(df)\n",
    "    df = process_fare(df)\n",
    "    df = process_titles(df)\n",
    "    df = process_cabin(df)\n",
    "    \n",
    "    for column in ['Age_categories', 'Fare_categories', 'Title', 'Cabin_type', 'Sex']:\n",
    "        df = create_dummies(df, column)\n",
    "        \n",
    "    return df\n",
    "\n",
    "# Create new features\n",
    "def process_family(df):\n",
    "    \"\"\"Create Family_size column calculated from Parch and SibSp\n",
    "\n",
    "    Usage\n",
    "    ------\n",
    "\n",
    "    train = process_family(train)\n",
    "    \"\"\"\n",
    "    df['familysize'] = df.apply(lambda row: row['Parch'] + row['SibSp'], axis=1)\n",
    "    return df\n",
    "\n",
    "def process_isalone(df):\n",
    "    df['isalone'] = (df['familysize'] == 0).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = preprocess_df(train)\n",
    "holdout = preprocess_df(holdout)\n",
    "\n",
    "train = process_family(train)\n",
    "train = process_isalone(train)\n",
    "\n",
    "holdout = process_family(holdout)\n",
    "holdout = process_isalone(holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Age_categories_Missing',\n",
      "       'Age_categories_Infant', 'Age_categories_Child',\n",
      "       'Age_categories_Teenager', 'Age_categories_Young Adult',\n",
      "       'Age_categories_Adult', 'Age_categories_Senior', 'Fare_categories_0-12',\n",
      "       'Fare_categories_12-50', 'Fare_categories_50-100',\n",
      "       'Fare_categories_100+', 'Title_Master', 'Title_Miss', 'Title_Mr',\n",
      "       'Title_Mrs', 'Title_Officer', 'Title_Royalty', 'Cabin_type_A',\n",
      "       'Cabin_type_B', 'Cabin_type_C', 'Cabin_type_D', 'Cabin_type_E',\n",
      "       'Cabin_type_F', 'Cabin_type_G', 'Cabin_type_Unknown', 'Sex_female',\n",
      "       'Sex_male', 'familysize', 'isalone'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def select_features(df):\n",
    "    # df is copied\n",
    "    # remove non-numeric\n",
    "    df = df.select_dtypes([np.number])\n",
    "    # remove NaNs\n",
    "    df = df.dropna(axis=1)\n",
    "    # create all_X (without PassengerId and Survived) and all_y\n",
    "    columns_to_drop = ['PassengerId']\n",
    "    df = df.drop(columns_to_drop, axis=1)\n",
    "    target_column = 'Survived'\n",
    "    all_X = df.drop(target_column, axis=1)\n",
    "    all_y = df[target_column]\n",
    "    # use RFECV with RandomForest - all_X, all_y, random_state=1, cv=10\n",
    "    rf = RandomForestClassifier(random_state=1)\n",
    "    selector = RFECV(rf, cv=10)\n",
    "    selector.fit(all_X, all_y)\n",
    "\n",
    "    best_columns = all_X.columns[selector.support_]\n",
    "    print(best_columns)\n",
    "    return best_columns\n",
    "\n",
    "best_columns = select_features(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "params: {'solver': 'lbfgs'}\n",
      "score: 0.819304152637486\n",
      "\n",
      "KNeighborsClassifier\n",
      "params: {'algorithm': 'kd_tree', 'n_neighbors': 3, 'p': 1, 'weights': 'uniform'}\n",
      "score: 0.7800224466891134\n",
      "\n",
      "RandomForestClassifier\n",
      "params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 6}\n",
      "score: 0.8395061728395061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def get_models_grid(df, columns):\n",
    "    target_column = 'Survived'\n",
    "    all_X = df[columns]\n",
    "    all_y = df[target_column]\n",
    "    models_grid = [\n",
    "        {\n",
    "            'name': 'LogisticRegression',\n",
    "            'estimator': LogisticRegression(),\n",
    "            'hyperparameters': {\n",
    "                'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'name': 'KNeighborsClassifier',\n",
    "            'estimator': KNeighborsClassifier(),\n",
    "            'hyperparameters': {\n",
    "                'n_neighbors': range(1, 20, 2),\n",
    "                'weights': ['distance', 'uniform'],\n",
    "                'algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
    "                'p': [1, 2],\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'name': 'RandomForestClassifier',\n",
    "            'estimator': RandomForestClassifier(),\n",
    "            'hyperparameters': {\n",
    "                'n_estimators': [4, 6, 9],\n",
    "                'criterion': ['entropy', 'gini'],\n",
    "                'max_depth': [2, 5, 10],\n",
    "                'max_features': ['log2', 'sqrt'],\n",
    "                'min_samples_leaf': [1, 5, 8],\n",
    "                'min_samples_split': [2, 3, 5],\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    for model in models_grid:\n",
    "        print(model['name'])\n",
    "        grid = GridSearchCV(model['estimator'], param_grid=model['hyperparameters'], cv=10)\n",
    "        grid.fit(all_X, all_y)\n",
    "        model['best_params'] = grid.best_params_\n",
    "        model['best_score'] = grid.best_score_\n",
    "        model['best_estimator'] = grid.best_estimator_\n",
    "        print('params: {}\\nscore: {}\\n'.format(model['best_params'], model['best_score']))\n",
    "    return models_grid\n",
    "\n",
    "models_grid = get_models_grid(train, best_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(models_grid):\n",
    "    best_score = 0.0\n",
    "    best_model = None\n",
    "    for model in models_grid:\n",
    "        if model['best_score'] > best_score:\n",
    "            best_score = model['best_score']\n",
    "            best_model = model['best_estimator']\n",
    "    return best_model\n",
    "\n",
    "best_model = get_best_model(models_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission_file(model, columns, filename='submission.csv'):\n",
    "    holdout_prediction = model.predict(holdout[columns])\n",
    "    submission = pd.DataFrame({'PassengerId': holdout['PassengerId'], 'Survived': holdout_prediction})\n",
    "    submission.to_csv(filename, index=False)\n",
    "\n",
    "save_submission_file(best_model, best_columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanic",
   "language": "python",
   "name": "titanic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
